{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RePlicator [Tool Notebook].ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNoV+AKx/zf2T1KmmqA8M4H",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arindamkeswani/RePlicator/blob/main/RePlicator_%5BTool_Notebook%5D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dr_qZkqGLmzB"
      },
      "source": [
        "#**Research Summary:**\n",
        "- 4 methodologies were implemented, tested, and compared, with time as the deciding metric:\n",
        "  1. Serial implementation (for base time)\n",
        "  2. Multiprocessing library (for base data-parallelism time)\n",
        "  3. Psuedo data-parallelism (purely for research purposes)\n",
        "  4. Numba library (for potential in-built optimum time)\n",
        "- 5 Tests done on each methodology:\n",
        "  1. Miniature Data [3 mini-files]\n",
        "  2. Actual data [10 files]\n",
        "  3. Actual data [26 files] [In-built cosine similarity]\n",
        "  4. Actual data [26 files] [Manual cosine similarity]\n",
        "  5. Actual data [50 files] [Manual cosine similarity]\n",
        "- Mid-size dataset (20-30 files) saw a speed-up of `19.42%`, as compared to Serial time\n",
        "- Large-size dataset (50+ files) saw a speed-up of `28.74%`, as compared to Serial time\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6UQAez_i-PLL"
      },
      "source": [
        "#**Description:**\n",
        "RePlicator (Relative Plagiarism Indicator) is a plagiarism indication tool meant to reduce the time taken to calculate level of plagiarism of a document with all the others in a dataset by using concepts of data-parallelism and libraries that work on similar principles.\n",
        "\n",
        "Application targets can include research facilities, universities, etc. who need a comparative analysis of a certain set of documents.\n",
        "\n",
        "Initially meant to be a research project, it was converted into an open-source tool with colab as its supporting platform, which enables users to use the tool **without worrying about licenses, hosting fees, and wasting memory on heavy applications.**\n",
        "\n",
        "\n",
        "Currently supported file types: \n",
        "- .pdf\n",
        "- .txt\n",
        "\n",
        "**All the user needs to do is run the code cells step-by-step (guide below).**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_h_hxI4-THk"
      },
      "source": [
        "#Steps to use the tool:\n",
        "To run a code cell, simply press `[Shift + Enter]`\n",
        "\n",
        "Follow the below steps in sequence\n",
        "1. Click `Connect` on top right of the screen to **connect to the server**. You should see a green tick in a few seconds\n",
        "2. Run cell in `Section 0` to **Import necessary libraries** for the tool to work\n",
        "3. Run cell in `Section 1` to **Upload files**, when prompted\n",
        "4. Run cell in `Section 2` for **PDF file processing**\n",
        "5. Run cell in `Section 3` to **Check plagiarism**\n",
        "6. Run cell in `Section 4` to **Display full table**\n",
        "7. Run cell in `Section 5` to **Download full table**\n",
        "8. Run cell in `Section 6` to **Download summarized table**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXiexgXzDq6T"
      },
      "source": [
        "#**Section 0 : Import libraries**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K3_jI4vy-EC9",
        "outputId": "f6f61728-9d65-4b04-b66b-c022e60b9dc9"
      },
      "source": [
        "import os\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "import time\n",
        "import pandas as pd\n",
        "from numba import jit\n",
        "from numba import njit\n",
        "\n",
        "from os import system\n",
        "import sys\n",
        "from numpy import dot #Alt for cosine similarity\n",
        "from numpy.linalg import norm #Alt for cosine similarity\n",
        "\n",
        "import multiprocessing\n",
        "\n",
        "!pip install PyPDF2\n",
        "import PyPDF2 \n",
        "\n",
        "# !pip install nltk\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "from google.colab import files \n",
        "\n",
        "\n",
        "print(\"__________________________________________\\n\\nALL LIBRARIES IMPORTED\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.7/dist-packages (1.26.0)\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "__________________________________________\n",
            "\n",
            "ALL LIBRARIES IMPORTED\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NAz7XRE2Eg-L"
      },
      "source": [
        "#**Section 1 : Upload files**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7CgpmdW5jdGlvbiBfdXBsb2FkRmlsZXMoaW5wdXRJZCwgb3V0cHV0SWQpIHsKICBjb25zdCBzdGVwcyA9IHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCk7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICAvLyBDYWNoZSBzdGVwcyBvbiB0aGUgb3V0cHV0RWxlbWVudCB0byBtYWtlIGl0IGF2YWlsYWJsZSBmb3IgdGhlIG5leHQgY2FsbAogIC8vIHRvIHVwbG9hZEZpbGVzQ29udGludWUgZnJvbSBQeXRob24uCiAgb3V0cHV0RWxlbWVudC5zdGVwcyA9IHN0ZXBzOwoKICByZXR1cm4gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpOwp9CgovLyBUaGlzIGlzIHJvdWdobHkgYW4gYXN5bmMgZ2VuZXJhdG9yIChub3Qgc3VwcG9ydGVkIGluIHRoZSBicm93c2VyIHlldCksCi8vIHdoZXJlIHRoZXJlIGFyZSBtdWx0aXBsZSBhc3luY2hyb25vdXMgc3RlcHMgYW5kIHRoZSBQeXRob24gc2lkZSBpcyBnb2luZwovLyB0byBwb2xsIGZvciBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcC4KLy8gVGhpcyB1c2VzIGEgUHJvbWlzZSB0byBibG9jayB0aGUgcHl0aG9uIHNpZGUgb24gY29tcGxldGlvbiBvZiBlYWNoIHN0ZXAsCi8vIHRoZW4gcGFzc2VzIHRoZSByZXN1bHQgb2YgdGhlIHByZXZpb3VzIHN0ZXAgYXMgdGhlIGlucHV0IHRvIHRoZSBuZXh0IHN0ZXAuCmZ1bmN0aW9uIF91cGxvYWRGaWxlc0NvbnRpbnVlKG91dHB1dElkKSB7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICBjb25zdCBzdGVwcyA9IG91dHB1dEVsZW1lbnQuc3RlcHM7CgogIGNvbnN0IG5leHQgPSBzdGVwcy5uZXh0KG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSk7CiAgcmV0dXJuIFByb21pc2UucmVzb2x2ZShuZXh0LnZhbHVlLnByb21pc2UpLnRoZW4oKHZhbHVlKSA9PiB7CiAgICAvLyBDYWNoZSB0aGUgbGFzdCBwcm9taXNlIHZhbHVlIHRvIG1ha2UgaXQgYXZhaWxhYmxlIHRvIHRoZSBuZXh0CiAgICAvLyBzdGVwIG9mIHRoZSBnZW5lcmF0b3IuCiAgICBvdXRwdXRFbGVtZW50Lmxhc3RQcm9taXNlVmFsdWUgPSB2YWx1ZTsKICAgIHJldHVybiBuZXh0LnZhbHVlLnJlc3BvbnNlOwogIH0pOwp9CgovKioKICogR2VuZXJhdG9yIGZ1bmN0aW9uIHdoaWNoIGlzIGNhbGxlZCBiZXR3ZWVuIGVhY2ggYXN5bmMgc3RlcCBvZiB0aGUgdXBsb2FkCiAqIHByb2Nlc3MuCiAqIEBwYXJhbSB7c3RyaW5nfSBpbnB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIGlucHV0IGZpbGUgcGlja2VyIGVsZW1lbnQuCiAqIEBwYXJhbSB7c3RyaW5nfSBvdXRwdXRJZCBFbGVtZW50IElEIG9mIHRoZSBvdXRwdXQgZGlzcGxheS4KICogQHJldHVybiB7IUl0ZXJhYmxlPCFPYmplY3Q+fSBJdGVyYWJsZSBvZiBuZXh0IHN0ZXBzLgogKi8KZnVuY3Rpb24qIHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IGlucHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKGlucHV0SWQpOwogIGlucHV0RWxlbWVudC5kaXNhYmxlZCA9IGZhbHNlOwoKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIG91dHB1dEVsZW1lbnQuaW5uZXJIVE1MID0gJyc7CgogIGNvbnN0IHBpY2tlZFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgaW5wdXRFbGVtZW50LmFkZEV2ZW50TGlzdGVuZXIoJ2NoYW5nZScsIChlKSA9PiB7CiAgICAgIHJlc29sdmUoZS50YXJnZXQuZmlsZXMpOwogICAgfSk7CiAgfSk7CgogIGNvbnN0IGNhbmNlbCA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2J1dHRvbicpOwogIGlucHV0RWxlbWVudC5wYXJlbnRFbGVtZW50LmFwcGVuZENoaWxkKGNhbmNlbCk7CiAgY2FuY2VsLnRleHRDb250ZW50ID0gJ0NhbmNlbCB1cGxvYWQnOwogIGNvbnN0IGNhbmNlbFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgY2FuY2VsLm9uY2xpY2sgPSAoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9OwogIH0pOwoKICAvLyBXYWl0IGZvciB0aGUgdXNlciB0byBwaWNrIHRoZSBmaWxlcy4KICBjb25zdCBmaWxlcyA9IHlpZWxkIHsKICAgIHByb21pc2U6IFByb21pc2UucmFjZShbcGlja2VkUHJvbWlzZSwgY2FuY2VsUHJvbWlzZV0pLAogICAgcmVzcG9uc2U6IHsKICAgICAgYWN0aW9uOiAnc3RhcnRpbmcnLAogICAgfQogIH07CgogIGNhbmNlbC5yZW1vdmUoKTsKCiAgLy8gRGlzYWJsZSB0aGUgaW5wdXQgZWxlbWVudCBzaW5jZSBmdXJ0aGVyIHBpY2tzIGFyZSBub3QgYWxsb3dlZC4KICBpbnB1dEVsZW1lbnQuZGlzYWJsZWQgPSB0cnVlOwoKICBpZiAoIWZpbGVzKSB7CiAgICByZXR1cm4gewogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgICAgfQogICAgfTsKICB9CgogIGZvciAoY29uc3QgZmlsZSBvZiBmaWxlcykgewogICAgY29uc3QgbGkgPSBkb2N1bWVudC5jcmVhdGVFbGVtZW50KCdsaScpOwogICAgbGkuYXBwZW5kKHNwYW4oZmlsZS5uYW1lLCB7Zm9udFdlaWdodDogJ2JvbGQnfSkpOwogICAgbGkuYXBwZW5kKHNwYW4oCiAgICAgICAgYCgke2ZpbGUudHlwZSB8fCAnbi9hJ30pIC0gJHtmaWxlLnNpemV9IGJ5dGVzLCBgICsKICAgICAgICBgbGFzdCBtb2RpZmllZDogJHsKICAgICAgICAgICAgZmlsZS5sYXN0TW9kaWZpZWREYXRlID8gZmlsZS5sYXN0TW9kaWZpZWREYXRlLnRvTG9jYWxlRGF0ZVN0cmluZygpIDoKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgJ24vYSd9IC0gYCkpOwogICAgY29uc3QgcGVyY2VudCA9IHNwYW4oJzAlIGRvbmUnKTsKICAgIGxpLmFwcGVuZENoaWxkKHBlcmNlbnQpOwoKICAgIG91dHB1dEVsZW1lbnQuYXBwZW5kQ2hpbGQobGkpOwoKICAgIGNvbnN0IGZpbGVEYXRhUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICAgIGNvbnN0IHJlYWRlciA9IG5ldyBGaWxlUmVhZGVyKCk7CiAgICAgIHJlYWRlci5vbmxvYWQgPSAoZSkgPT4gewogICAgICAgIHJlc29sdmUoZS50YXJnZXQucmVzdWx0KTsKICAgICAgfTsKICAgICAgcmVhZGVyLnJlYWRBc0FycmF5QnVmZmVyKGZpbGUpOwogICAgfSk7CiAgICAvLyBXYWl0IGZvciB0aGUgZGF0YSB0byBiZSByZWFkeS4KICAgIGxldCBmaWxlRGF0YSA9IHlpZWxkIHsKICAgICAgcHJvbWlzZTogZmlsZURhdGFQcm9taXNlLAogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbnRpbnVlJywKICAgICAgfQogICAgfTsKCiAgICAvLyBVc2UgYSBjaHVua2VkIHNlbmRpbmcgdG8gYXZvaWQgbWVzc2FnZSBzaXplIGxpbWl0cy4gU2VlIGIvNjIxMTU2NjAuCiAgICBsZXQgcG9zaXRpb24gPSAwOwogICAgZG8gewogICAgICBjb25zdCBsZW5ndGggPSBNYXRoLm1pbihmaWxlRGF0YS5ieXRlTGVuZ3RoIC0gcG9zaXRpb24sIE1BWF9QQVlMT0FEX1NJWkUpOwogICAgICBjb25zdCBjaHVuayA9IG5ldyBVaW50OEFycmF5KGZpbGVEYXRhLCBwb3NpdGlvbiwgbGVuZ3RoKTsKICAgICAgcG9zaXRpb24gKz0gbGVuZ3RoOwoKICAgICAgY29uc3QgYmFzZTY0ID0gYnRvYShTdHJpbmcuZnJvbUNoYXJDb2RlLmFwcGx5KG51bGwsIGNodW5rKSk7CiAgICAgIHlpZWxkIHsKICAgICAgICByZXNwb25zZTogewogICAgICAgICAgYWN0aW9uOiAnYXBwZW5kJywKICAgICAgICAgIGZpbGU6IGZpbGUubmFtZSwKICAgICAgICAgIGRhdGE6IGJhc2U2NCwKICAgICAgICB9LAogICAgICB9OwoKICAgICAgbGV0IHBlcmNlbnREb25lID0gZmlsZURhdGEuYnl0ZUxlbmd0aCA9PT0gMCA/CiAgICAgICAgICAxMDAgOgogICAgICAgICAgTWF0aC5yb3VuZCgocG9zaXRpb24gLyBmaWxlRGF0YS5ieXRlTGVuZ3RoKSAqIDEwMCk7CiAgICAgIHBlcmNlbnQudGV4dENvbnRlbnQgPSBgJHtwZXJjZW50RG9uZX0lIGRvbmVgOwoKICAgIH0gd2hpbGUgKHBvc2l0aW9uIDwgZmlsZURhdGEuYnl0ZUxlbmd0aCk7CiAgfQoKICAvLyBBbGwgZG9uZS4KICB5aWVsZCB7CiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICB9CiAgfTsKfQoKc2NvcGUuZ29vZ2xlID0gc2NvcGUuZ29vZ2xlIHx8IHt9OwpzY29wZS5nb29nbGUuY29sYWIgPSBzY29wZS5nb29nbGUuY29sYWIgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYi5fZmlsZXMgPSB7CiAgX3VwbG9hZEZpbGVzLAogIF91cGxvYWRGaWxlc0NvbnRpbnVlLAp9Owp9KShzZWxmKTsK",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "id": "XpVasLh-EiGn",
        "outputId": "ed3fa8fb-f261-404a-ae12-d25702f1f144"
      },
      "source": [
        "uploaded = files.upload()\n",
        "\n",
        "print(\"__________________________________________\\n\\nALL FILES UPLOADED\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-11b0a75a-cb82-43db-937b-f112a04ad151\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-11b0a75a-cb82-43db-937b-f112a04ad151\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving Foucault5.pdf to Foucault5.pdf\n",
            "Saving Foucault6.pdf to Foucault6.pdf\n",
            "Saving Foucault7.pdf to Foucault7.pdf\n",
            "Saving Foucault8.pdf to Foucault8.pdf\n",
            "Saving Gender1.pdf to Gender1.pdf\n",
            "Saving john.txt to john.txt\n",
            "Saving juma.txt to juma.txt\n",
            "Saving ML1.pdf to ML1.pdf\n",
            "Saving ML2.pdf to ML2.pdf\n",
            "Saving PatFem1.txt to PatFem1.txt\n",
            "Saving PatFem3.pdf to PatFem3.pdf\n",
            "__________________________________________\n",
            "\n",
            "ALL FILES UPLOADED\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jkv6TdEIFU9o"
      },
      "source": [
        "#**Section 2 : PDF File Processing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1-Eo37xFdeI",
        "outputId": "3b89fd5b-bd47-4920-aa63-5e2d5abc7f10"
      },
      "source": [
        "student_files_pdf = [doc for doc in os.listdir() if doc.endswith('.pdf')]\n",
        "\n",
        "# %%time\n",
        "#Multiprocessing approach\n",
        "# creating a pdf file object \n",
        "def convert2(student_files_pdf):\n",
        "  for i in student_files_pdf:\n",
        "    try:\n",
        "      path=i\n",
        "      pin='/content/'+path\n",
        "      print(f\"Converting {pin.split('/')[-1]}...\")\n",
        "      pout=pin[:-4]+\".txt\"\n",
        "      print(pout)\n",
        "      pdfFileObj = open(pin, 'rb') \n",
        "          \n",
        "      # creating a pdf reader object \n",
        "      pdfReader = PyPDF2.PdfFileReader(pdfFileObj) \n",
        "          \n",
        "      # printing number of pages in pdf file \n",
        "      print(f\"Number of pages: {pdfReader.numPages}\") \n",
        "          \n",
        "      # creating a page object \n",
        "      s=\"\"\n",
        "      for i in range(pdfReader.numPages):\n",
        "        pageObj = pdfReader.getPage(i) \n",
        "          \n",
        "        # extracting text from page \n",
        "        \n",
        "        s+=pageObj.extractText()\n",
        "      print(f\"Writing contents of {pin} to {pout}\")\n",
        "      myText = open(pout,'w')\n",
        "\n",
        "      stop_words = set(stopwords.words('english'))\n",
        " \n",
        "      word_tokens = word_tokenize(s)\n",
        "      filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]\n",
        " \n",
        "      filtered_sentence = []\n",
        "      \n",
        "      for w in word_tokens:\n",
        "          if w not in stop_words:\n",
        "              filtered_sentence.append(w)\n",
        "      \n",
        "      sp = \" \"\n",
        "  \n",
        "      # joins elements of list1 by '-'\n",
        "      # and stores in sting s\n",
        "\n",
        "      filter_joined = sp.join(filtered_sentence)\n",
        "      myText.write(filter_joined)\n",
        "      myText.close()\n",
        "      pdfFileObj.close()\n",
        "      print('_'*100)\n",
        "    except:\n",
        "      print(\"Cannot convert\",i)\n",
        "      print('_'*100)\n",
        "  \n",
        "pool = multiprocessing.Pool(processes=2) \n",
        "\n",
        "\n",
        "\n",
        "l1 = student_files_pdf[:len(student_files_pdf)//2]\n",
        "l2 = student_files_pdf[len(student_files_pdf)//2:]\n",
        "\n",
        "start=time.time()\n",
        "\n",
        "result = pool.map(convert2, [l1,l2])\n",
        "\n",
        "for i in result:\n",
        "  print(i)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Converting Cloud2.pdf...\n",
            "/content/Cloud2.txt\n",
            "Converting Foucault7.pdf...\n",
            "/content/Foucault7.txt\n",
            "Number of pages: 20\n",
            "Number of pages: 133\n",
            "Writing contents of /content/Foucault7.pdf to /content/Foucault7.txt\n",
            "____________________________________________________________________________________________________\n",
            "Converting Foucault6.pdf...\n",
            "/content/Foucault6.txt\n",
            "Number of pages: 3\n",
            "Writing contents of /content/Foucault6.pdf to /content/Foucault6.txt\n",
            "____________________________________________________________________________________________________\n",
            "Converting Foucault1.pdf...\n",
            "/content/Foucault1.txt\n",
            "Number of pages: 4\n",
            "Writing contents of /content/Foucault1.pdf to /content/Foucault1.txt\n",
            "____________________________________________________________________________________________________\n",
            "Converting ML1.pdf...\n",
            "/content/ML1.txt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "PdfReadWarning: Xref table not zero-indexed. ID numbers for objects will be corrected. [pdf.py:1736]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Number of pages: 18\n",
            "Writing contents of /content/ML1.pdf to /content/ML1.txt\n",
            "____________________________________________________________________________________________________\n",
            "Converting Capitalism.pdf...\n",
            "/content/Capitalism.txt\n",
            "Number of pages: 10\n",
            "Writing contents of /content/Capitalism.pdf to /content/Capitalism.txt\n",
            "____________________________________________________________________________________________________\n",
            "Converting ML2.pdf...\n",
            "/content/ML2.txt\n",
            "Number of pages: 30\n",
            "Writing contents of /content/ML2.pdf to /content/ML2.txt\n",
            "____________________________________________________________________________________________________\n",
            "Converting Foucault5.pdf...\n",
            "/content/Foucault5.txt\n",
            "Number of pages: 15\n",
            "Writing contents of /content/Foucault5.pdf to /content/Foucault5.txt\n",
            "____________________________________________________________________________________________________\n",
            "Writing contents of /content/Cloud2.pdf to /content/Cloud2.txt\n",
            "____________________________________________________________________________________________________\n",
            "Converting Gender1.pdf...\n",
            "/content/Gender1.txt\n",
            "Number of pages: 4\n",
            "Writing contents of /content/Gender1.pdf to /content/Gender1.txt\n",
            "____________________________________________________________________________________________________\n",
            "Converting Cloud1.pdf...\n",
            "/content/Cloud1.txt\n",
            "Number of pages: 47\n",
            "Writing contents of /content/Cloud1.pdf to /content/Cloud1.txt\n",
            "____________________________________________________________________________________________________\n",
            "Converting Foucault8.pdf...\n",
            "/content/Foucault8.txt\n",
            "Number of pages: 7\n",
            "Writing contents of /content/Foucault8.pdf to /content/Foucault8.txt\n",
            "____________________________________________________________________________________________________\n",
            "Converting PatFem3.pdf...\n",
            "/content/PatFem3.txt\n",
            "Number of pages: 21\n",
            "Writing contents of /content/PatFem3.pdf to /content/PatFem3.txt\n",
            "____________________________________________________________________________________________________\n",
            "Converting Foucault2.pdf...\n",
            "/content/Foucault2.txt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "PdfReadWarning: Xref table not zero-indexed. ID numbers for objects will be corrected. [pdf.py:1736]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Number of pages: 19\n",
            "Writing contents of /content/Foucault2.pdf to /content/Foucault2.txt\n",
            "____________________________________________________________________________________________________\n",
            "None\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-XXLJcrJFd2S"
      },
      "source": [
        "#**Section 3 : Check plagiarism**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwmfVPGXFkh1",
        "outputId": "1fa8fbc2-10eb-4d0d-973f-2f912d40916d"
      },
      "source": [
        "student_files = [doc for doc in os.listdir() if doc.endswith('.txt')] #store all text files\n",
        "student_notes =[open(File).read() for File in  student_files] #stores all lines of all files\n",
        "\n",
        "vectorize = lambda Text: TfidfVectorizer().fit_transform(Text).toarray()  #to vectorize the words of text files\n",
        "\n",
        "vectors = vectorize(student_notes) #store vectorized values\n",
        "s_vectors = list(zip(student_files, vectors)) #store it with file names\n",
        "plagiarism_results =[]\n",
        "\n",
        "def check_plagiarism(s_vectors_partial):\n",
        "    # similarity = lambda doc1, doc2: cosine_similarity([doc1, doc2]) #to store similarity of two documents\n",
        "    plagiarism_results =[]\n",
        "    \n",
        "    sys.stdout.write(\"\\r\"+\"Starting process...\")\n",
        "    global s_vectors\n",
        "    for student_a, text_vector_a in s_vectors_partial:  #traverse through students and their vectors (for first document)\n",
        "        # print(f\"Started testing:{student_a}\")\n",
        "        # print(\"Started testing:\",student_a)\n",
        "        sys.stdout.write(\"\\r\"+\"Started testing:\"+student_a) # Cursor up one line\n",
        "        # time.sleep(1)\n",
        "        new_vectors = s_vectors.copy() \n",
        "        \n",
        "        # current_index = new_vectors.index((student_a, text_vector_a))\n",
        "        # del new_vectors[current_index]\n",
        "        \n",
        "\n",
        "        for student_b , text_vector_b in new_vectors: #traverse through students and their vectors (for second document)\n",
        "            # print(f\"Testing {student_a} against {student_b}\")\n",
        "            # print(\"Testing\",student_a,\"against\",student_b)\n",
        "            sys.stdout.write(\"\\r\"+\"Testing: \"+student_a+\" | Against: \"+student_b) # Cursor up one line\n",
        "            # time.sleep(1)\n",
        "            # sim_score = similarity(text_vector_a, text_vector_b)[0][1] #calculate similarity of both documents\n",
        "            sim_score = dot(text_vector_a, text_vector_b)/(norm(text_vector_a)*norm(text_vector_b))\n",
        "            # sim_score = cosine_similarity([text_vector_a, text_vector_b])[0][1]#########################Uncomment it later\n",
        "            # student_pair = sorted((student_a, student_b)) \n",
        "            student_pair = (student_a, student_b) \n",
        "            # score = (student_pair[0], student_pair[1],sim_score)\n",
        "            score = [student_pair[0], student_pair[1],float(\"%.2f\" % round(sim_score*100, 2))]\n",
        "            # plagiarism_results.add(score) #add score with file names into the set\n",
        "            plagiarism_results.append(score)\n",
        "            # print(\"Finished testing\",student_a,\"against\",student_b)\n",
        "        sys.stdout.write(\"\\r\"+\"Finished testing: \"+student_a)\n",
        "        sys.stdout.write(\"\\r\")\n",
        "        # print()\n",
        "    sys.stdout.write(\"\\r\"+\"TESTING COMPLETE!\")\n",
        "    return plagiarism_results  \n",
        "    # return createTable(plagiarism_results)\n",
        "\n",
        "def createTable(ans):\n",
        "    df=pd.DataFrame(np.zeros((len(student_files),len(student_files))),index=student_files,columns=student_files)\n",
        "\n",
        "    for data in ans:\n",
        "      for rowName in range(len(student_files)):\n",
        "        if df.index[rowName]==data[0]:\n",
        "          r=rowName\n",
        "          for colName in range(len(student_files)):\n",
        "            if df.index[colName]==data[1]:\n",
        "              c=colName\n",
        "\n",
        "              df.iloc[r,c] = data[2]\n",
        "    return df\n",
        "num_res= jit(parallel=True,forceobj=True)(check_plagiarism)\n",
        "ans=num_res(s_vectors)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TESTING COMPLETE!"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rps8DrkvFk9O"
      },
      "source": [
        "#**Section 4 : Full table**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 562
        },
        "id": "ZFyZ5aEMFoFf",
        "outputId": "a7e588df-20c1-4080-bdbe-05f3a8911cdd"
      },
      "source": [
        "df=createTable(ans)\n",
        "df"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ML2.txt</th>\n",
              "      <th>Cloud2.txt</th>\n",
              "      <th>Capitalism.txt</th>\n",
              "      <th>PatFem3.txt</th>\n",
              "      <th>PatFem1.txt</th>\n",
              "      <th>Cloud1.txt</th>\n",
              "      <th>john.txt</th>\n",
              "      <th>Foucault5.txt</th>\n",
              "      <th>Foucault1.txt</th>\n",
              "      <th>Foucault2.txt</th>\n",
              "      <th>juma.txt</th>\n",
              "      <th>Foucault8.txt</th>\n",
              "      <th>Gender1.txt</th>\n",
              "      <th>Foucault7.txt</th>\n",
              "      <th>ML1.txt</th>\n",
              "      <th>Foucault6.txt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ML2.txt</th>\n",
              "      <td>100.00</td>\n",
              "      <td>1.33</td>\n",
              "      <td>1.38</td>\n",
              "      <td>0.02</td>\n",
              "      <td>1.85</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2.36</td>\n",
              "      <td>0.54</td>\n",
              "      <td>1.13</td>\n",
              "      <td>0.90</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.95</td>\n",
              "      <td>1.84</td>\n",
              "      <td>0.81</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Cloud2.txt</th>\n",
              "      <td>1.33</td>\n",
              "      <td>100.00</td>\n",
              "      <td>3.13</td>\n",
              "      <td>0.09</td>\n",
              "      <td>11.68</td>\n",
              "      <td>3.27</td>\n",
              "      <td>8.04</td>\n",
              "      <td>7.67</td>\n",
              "      <td>4.85</td>\n",
              "      <td>8.84</td>\n",
              "      <td>2.95</td>\n",
              "      <td>5.24</td>\n",
              "      <td>6.39</td>\n",
              "      <td>7.28</td>\n",
              "      <td>16.59</td>\n",
              "      <td>4.92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Capitalism.txt</th>\n",
              "      <td>1.38</td>\n",
              "      <td>3.13</td>\n",
              "      <td>100.00</td>\n",
              "      <td>0.06</td>\n",
              "      <td>3.82</td>\n",
              "      <td>0.41</td>\n",
              "      <td>1.80</td>\n",
              "      <td>9.25</td>\n",
              "      <td>7.26</td>\n",
              "      <td>10.83</td>\n",
              "      <td>2.10</td>\n",
              "      <td>4.94</td>\n",
              "      <td>6.45</td>\n",
              "      <td>9.57</td>\n",
              "      <td>2.83</td>\n",
              "      <td>5.92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PatFem3.txt</th>\n",
              "      <td>0.02</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.06</td>\n",
              "      <td>100.00</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.27</td>\n",
              "      <td>0.51</td>\n",
              "      <td>0.90</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.49</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.99</td>\n",
              "      <td>0.33</td>\n",
              "      <td>0.37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PatFem1.txt</th>\n",
              "      <td>1.85</td>\n",
              "      <td>11.68</td>\n",
              "      <td>3.82</td>\n",
              "      <td>0.60</td>\n",
              "      <td>100.00</td>\n",
              "      <td>0.89</td>\n",
              "      <td>10.82</td>\n",
              "      <td>14.23</td>\n",
              "      <td>9.03</td>\n",
              "      <td>15.49</td>\n",
              "      <td>17.76</td>\n",
              "      <td>8.35</td>\n",
              "      <td>20.96</td>\n",
              "      <td>16.59</td>\n",
              "      <td>10.38</td>\n",
              "      <td>9.53</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Cloud1.txt</th>\n",
              "      <td>0.28</td>\n",
              "      <td>3.27</td>\n",
              "      <td>0.41</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.89</td>\n",
              "      <td>100.00</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.29</td>\n",
              "      <td>0.79</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.39</td>\n",
              "      <td>0.42</td>\n",
              "      <td>0.47</td>\n",
              "      <td>0.48</td>\n",
              "      <td>0.33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>john.txt</th>\n",
              "      <td>0.00</td>\n",
              "      <td>8.04</td>\n",
              "      <td>1.80</td>\n",
              "      <td>0.00</td>\n",
              "      <td>10.82</td>\n",
              "      <td>0.09</td>\n",
              "      <td>100.00</td>\n",
              "      <td>1.91</td>\n",
              "      <td>1.35</td>\n",
              "      <td>2.19</td>\n",
              "      <td>63.87</td>\n",
              "      <td>2.54</td>\n",
              "      <td>0.93</td>\n",
              "      <td>1.66</td>\n",
              "      <td>0.61</td>\n",
              "      <td>3.52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Foucault5.txt</th>\n",
              "      <td>2.36</td>\n",
              "      <td>7.67</td>\n",
              "      <td>9.25</td>\n",
              "      <td>0.27</td>\n",
              "      <td>14.23</td>\n",
              "      <td>0.60</td>\n",
              "      <td>1.91</td>\n",
              "      <td>100.00</td>\n",
              "      <td>12.35</td>\n",
              "      <td>25.43</td>\n",
              "      <td>3.30</td>\n",
              "      <td>18.80</td>\n",
              "      <td>6.85</td>\n",
              "      <td>15.25</td>\n",
              "      <td>7.19</td>\n",
              "      <td>14.76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Foucault1.txt</th>\n",
              "      <td>0.54</td>\n",
              "      <td>4.85</td>\n",
              "      <td>7.26</td>\n",
              "      <td>0.51</td>\n",
              "      <td>9.03</td>\n",
              "      <td>0.29</td>\n",
              "      <td>1.35</td>\n",
              "      <td>12.35</td>\n",
              "      <td>100.00</td>\n",
              "      <td>18.76</td>\n",
              "      <td>3.13</td>\n",
              "      <td>11.59</td>\n",
              "      <td>5.10</td>\n",
              "      <td>10.93</td>\n",
              "      <td>5.03</td>\n",
              "      <td>16.78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Foucault2.txt</th>\n",
              "      <td>1.13</td>\n",
              "      <td>8.84</td>\n",
              "      <td>10.83</td>\n",
              "      <td>0.90</td>\n",
              "      <td>15.49</td>\n",
              "      <td>0.79</td>\n",
              "      <td>2.19</td>\n",
              "      <td>25.43</td>\n",
              "      <td>18.76</td>\n",
              "      <td>100.00</td>\n",
              "      <td>4.20</td>\n",
              "      <td>38.67</td>\n",
              "      <td>13.71</td>\n",
              "      <td>28.23</td>\n",
              "      <td>8.98</td>\n",
              "      <td>37.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>juma.txt</th>\n",
              "      <td>0.90</td>\n",
              "      <td>2.95</td>\n",
              "      <td>2.10</td>\n",
              "      <td>0.00</td>\n",
              "      <td>17.76</td>\n",
              "      <td>0.16</td>\n",
              "      <td>63.87</td>\n",
              "      <td>3.30</td>\n",
              "      <td>3.13</td>\n",
              "      <td>4.20</td>\n",
              "      <td>100.00</td>\n",
              "      <td>4.45</td>\n",
              "      <td>1.05</td>\n",
              "      <td>2.52</td>\n",
              "      <td>1.18</td>\n",
              "      <td>5.09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Foucault8.txt</th>\n",
              "      <td>0.88</td>\n",
              "      <td>5.24</td>\n",
              "      <td>4.94</td>\n",
              "      <td>0.49</td>\n",
              "      <td>8.35</td>\n",
              "      <td>0.39</td>\n",
              "      <td>2.54</td>\n",
              "      <td>18.80</td>\n",
              "      <td>11.59</td>\n",
              "      <td>38.67</td>\n",
              "      <td>4.45</td>\n",
              "      <td>100.00</td>\n",
              "      <td>6.70</td>\n",
              "      <td>17.90</td>\n",
              "      <td>4.29</td>\n",
              "      <td>22.72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Gender1.txt</th>\n",
              "      <td>0.70</td>\n",
              "      <td>6.39</td>\n",
              "      <td>6.45</td>\n",
              "      <td>0.24</td>\n",
              "      <td>20.96</td>\n",
              "      <td>0.42</td>\n",
              "      <td>0.93</td>\n",
              "      <td>6.85</td>\n",
              "      <td>5.10</td>\n",
              "      <td>13.71</td>\n",
              "      <td>1.05</td>\n",
              "      <td>6.70</td>\n",
              "      <td>100.00</td>\n",
              "      <td>12.97</td>\n",
              "      <td>5.13</td>\n",
              "      <td>6.67</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Foucault7.txt</th>\n",
              "      <td>0.95</td>\n",
              "      <td>7.28</td>\n",
              "      <td>9.57</td>\n",
              "      <td>0.99</td>\n",
              "      <td>16.59</td>\n",
              "      <td>0.47</td>\n",
              "      <td>1.66</td>\n",
              "      <td>15.25</td>\n",
              "      <td>10.93</td>\n",
              "      <td>28.23</td>\n",
              "      <td>2.52</td>\n",
              "      <td>17.90</td>\n",
              "      <td>12.97</td>\n",
              "      <td>100.00</td>\n",
              "      <td>7.29</td>\n",
              "      <td>18.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ML1.txt</th>\n",
              "      <td>1.84</td>\n",
              "      <td>16.59</td>\n",
              "      <td>2.83</td>\n",
              "      <td>0.33</td>\n",
              "      <td>10.38</td>\n",
              "      <td>0.48</td>\n",
              "      <td>0.61</td>\n",
              "      <td>7.19</td>\n",
              "      <td>5.03</td>\n",
              "      <td>8.98</td>\n",
              "      <td>1.18</td>\n",
              "      <td>4.29</td>\n",
              "      <td>5.13</td>\n",
              "      <td>7.29</td>\n",
              "      <td>100.00</td>\n",
              "      <td>5.76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Foucault6.txt</th>\n",
              "      <td>0.81</td>\n",
              "      <td>4.92</td>\n",
              "      <td>5.92</td>\n",
              "      <td>0.37</td>\n",
              "      <td>9.53</td>\n",
              "      <td>0.33</td>\n",
              "      <td>3.52</td>\n",
              "      <td>14.76</td>\n",
              "      <td>16.78</td>\n",
              "      <td>37.05</td>\n",
              "      <td>5.09</td>\n",
              "      <td>22.72</td>\n",
              "      <td>6.67</td>\n",
              "      <td>18.05</td>\n",
              "      <td>5.76</td>\n",
              "      <td>100.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                ML2.txt  Cloud2.txt  ...  ML1.txt  Foucault6.txt\n",
              "ML2.txt          100.00        1.33  ...     1.84           0.81\n",
              "Cloud2.txt         1.33      100.00  ...    16.59           4.92\n",
              "Capitalism.txt     1.38        3.13  ...     2.83           5.92\n",
              "PatFem3.txt        0.02        0.09  ...     0.33           0.37\n",
              "PatFem1.txt        1.85       11.68  ...    10.38           9.53\n",
              "Cloud1.txt         0.28        3.27  ...     0.48           0.33\n",
              "john.txt           0.00        8.04  ...     0.61           3.52\n",
              "Foucault5.txt      2.36        7.67  ...     7.19          14.76\n",
              "Foucault1.txt      0.54        4.85  ...     5.03          16.78\n",
              "Foucault2.txt      1.13        8.84  ...     8.98          37.05\n",
              "juma.txt           0.90        2.95  ...     1.18           5.09\n",
              "Foucault8.txt      0.88        5.24  ...     4.29          22.72\n",
              "Gender1.txt        0.70        6.39  ...     5.13           6.67\n",
              "Foucault7.txt      0.95        7.28  ...     7.29          18.05\n",
              "ML1.txt            1.84       16.59  ...   100.00           5.76\n",
              "Foucault6.txt      0.81        4.92  ...     5.76         100.00\n",
              "\n",
              "[16 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fO6hRNHxFpnj"
      },
      "source": [
        "#**Section 5 : Summary table**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "JWPeJwREFqzR",
        "outputId": "56cbd144-d6c9-457b-8f6e-773a6629997d"
      },
      "source": [
        "df_res=pd.DataFrame()\n",
        "df_res[\"Max plag value\"]= df.apply(lambda row: row.nlargest(2).values[-1],axis=1)\n",
        "df_res[\"Max plag doc\"]= df.T.apply(lambda x: x.nlargest(2).idxmin())\n",
        "df_res[\"Average plag\"] = (df.sum(axis=1)-1) / (len(df)-1)\n",
        "df_res"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Max plag value</th>\n",
              "      <th>Max plag doc</th>\n",
              "      <th>Average plag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ML2.txt</th>\n",
              "      <td>2.36</td>\n",
              "      <td>Foucault5.txt</td>\n",
              "      <td>7.598000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Cloud2.txt</th>\n",
              "      <td>16.59</td>\n",
              "      <td>ML1.txt</td>\n",
              "      <td>12.751333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Capitalism.txt</th>\n",
              "      <td>10.83</td>\n",
              "      <td>Foucault2.txt</td>\n",
              "      <td>11.250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PatFem3.txt</th>\n",
              "      <td>0.99</td>\n",
              "      <td>Foucault7.txt</td>\n",
              "      <td>6.924667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PatFem1.txt</th>\n",
              "      <td>20.96</td>\n",
              "      <td>Gender1.txt</td>\n",
              "      <td>16.732000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Cloud1.txt</th>\n",
              "      <td>3.27</td>\n",
              "      <td>Cloud2.txt</td>\n",
              "      <td>7.191333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>john.txt</th>\n",
              "      <td>63.87</td>\n",
              "      <td>juma.txt</td>\n",
              "      <td>13.222000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Foucault5.txt</th>\n",
              "      <td>25.43</td>\n",
              "      <td>Foucault2.txt</td>\n",
              "      <td>15.948000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Foucault1.txt</th>\n",
              "      <td>18.76</td>\n",
              "      <td>Foucault2.txt</td>\n",
              "      <td>13.766667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Foucault2.txt</th>\n",
              "      <td>38.67</td>\n",
              "      <td>Foucault8.txt</td>\n",
              "      <td>20.946667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>juma.txt</th>\n",
              "      <td>63.87</td>\n",
              "      <td>john.txt</td>\n",
              "      <td>14.110667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Foucault8.txt</th>\n",
              "      <td>38.67</td>\n",
              "      <td>Foucault2.txt</td>\n",
              "      <td>16.463333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Gender1.txt</th>\n",
              "      <td>20.96</td>\n",
              "      <td>PatFem1.txt</td>\n",
              "      <td>12.884667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Foucault7.txt</th>\n",
              "      <td>28.23</td>\n",
              "      <td>Foucault2.txt</td>\n",
              "      <td>16.643333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ML1.txt</th>\n",
              "      <td>16.59</td>\n",
              "      <td>Cloud2.txt</td>\n",
              "      <td>11.794000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Foucault6.txt</th>\n",
              "      <td>37.05</td>\n",
              "      <td>Foucault2.txt</td>\n",
              "      <td>16.752000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                Max plag value   Max plag doc  Average plag\n",
              "ML2.txt                   2.36  Foucault5.txt      7.598000\n",
              "Cloud2.txt               16.59        ML1.txt     12.751333\n",
              "Capitalism.txt           10.83  Foucault2.txt     11.250000\n",
              "PatFem3.txt               0.99  Foucault7.txt      6.924667\n",
              "PatFem1.txt              20.96    Gender1.txt     16.732000\n",
              "Cloud1.txt                3.27     Cloud2.txt      7.191333\n",
              "john.txt                 63.87       juma.txt     13.222000\n",
              "Foucault5.txt            25.43  Foucault2.txt     15.948000\n",
              "Foucault1.txt            18.76  Foucault2.txt     13.766667\n",
              "Foucault2.txt            38.67  Foucault8.txt     20.946667\n",
              "juma.txt                 63.87       john.txt     14.110667\n",
              "Foucault8.txt            38.67  Foucault2.txt     16.463333\n",
              "Gender1.txt              20.96    PatFem1.txt     12.884667\n",
              "Foucault7.txt            28.23  Foucault2.txt     16.643333\n",
              "ML1.txt                  16.59     Cloud2.txt     11.794000\n",
              "Foucault6.txt            37.05  Foucault2.txt     16.752000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ThSstsOFFsMg"
      },
      "source": [
        "#**Section 6 : Download full table**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "VbUY7nSEFtHk",
        "outputId": "b0635401-d2f1-48fc-b303-c287317b2c00"
      },
      "source": [
        "df.to_csv('FullTable.csv')\n",
        "files.download('FullTable.csv')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_5a3d8fea-41b1-476f-8573-5d99628892a1\", \"FullTable.csv\", 541)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mc-hYEt-Ftk6"
      },
      "source": [
        "#**Section 7 : Download summary table**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "TibIOL5DFudP",
        "outputId": "ed004d3a-c5cd-4c5b-8d46-40ae42601116"
      },
      "source": [
        "df_res.to_csv('Summary.csv')\n",
        "files.download('Summary.csv')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_6c3b70b0-b855-454e-80b0-9dd1569a5b7c\", \"Summary.csv\", 365)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hX_2AO6FvhH"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    }
  ]
}