{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RePlicate (HPC Project).ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM14sDVTKiQv56mScee6PA0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arindamkeswani/RePlicate/blob/main/RePlicate_(HPC_Project).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "900cuLNHyOwm",
        "outputId": "6d6eb0f1-58f1-4705-f73d-75ff07d886af"
      },
      "source": [
        "from google.colab import files \n",
        "uploaded = files.upload()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-2c653125-f326-45f5-9637-74f71003e1ca\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-2c653125-f326-45f5-9637-74f71003e1ca\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving fatma.txt to fatma.txt\n",
            "Saving image.png to image.png\n",
            "Saving john.txt to john.txt\n",
            "Saving juma.txt to juma.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzcoSlXM8ODC"
      },
      "source": [
        "import os\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "import time"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJR7IIRm8mmD"
      },
      "source": [
        "student_files = [doc for doc in os.listdir() if doc.endswith('.txt')] #store all text files\n",
        "student_notes =[open(File).read() for File in  student_files] #stores all lines of all files"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qnz0F40y8wyQ"
      },
      "source": [
        "vectorize = lambda Text: TfidfVectorizer().fit_transform(Text).toarray()  #to vectorize the words of text files\n",
        "similarity = lambda doc1, doc2: cosine_similarity([doc1, doc2]) #to store similarity of two documents"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmHNPgDc9Yja"
      },
      "source": [
        "vectors = vectorize(student_notes) #store vectorized values\n",
        "s_vectors = list(zip(student_files, vectors)) #store it with file names\n",
        "plagiarism_results = set() #to store results in a set\n",
        "# plagiarism_results =[]\n"
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEjPd93g9Zss"
      },
      "source": [
        "def check_plagiarism(s_vectors_partial):\n",
        "    print(\"Starting process...\")\n",
        "    global s_vectors\n",
        "    for student_a, text_vector_a in s_vectors_partial:  #traverse through students and their vectors (for first document)\n",
        "        print(f\"Started testing:{student_a}\")\n",
        "        new_vectors = s_vectors.copy() \n",
        "        \n",
        "        # current_index = new_vectors.index((student_a, text_vector_a))\n",
        "        # del new_vectors[current_index]\n",
        "        \n",
        "\n",
        "        for student_b , text_vector_b in new_vectors: #traverse through students and their vectors (for first document)\n",
        "            print(f\"Testing {student_a} against {student_b}\")\n",
        "            sim_score = similarity(text_vector_a, text_vector_b)[0][1] #calculate similarity of both documents\n",
        "            student_pair = sorted((student_a, student_b)) \n",
        "            score = (student_pair[0], student_pair[1],sim_score)\n",
        "            # score = [student_pair[0], student_pair[1],sim_score]\n",
        "            plagiarism_results.add(score) #add score with file names into the set\n",
        "            # plagiarism_results.append(score)\n",
        "        print()\n",
        "    return plagiarism_results"
      ],
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YsKAiRP49jes",
        "outputId": "526912c5-e243-4c75-a35f-79a10a0aa4f1"
      },
      "source": [
        "#Serial\n",
        "start=time.time()\n",
        "ans=check_plagiarism(s_vectors)\n",
        "\n",
        "for data in ans:\n",
        "    print(data)\n",
        "end=time.time()\n",
        "print()\n",
        "print(\"Time taken:\", end-start)"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting process...\n",
            "Started testing:juma.txt\n",
            "Testing juma.txt against juma.txt\n",
            "Testing juma.txt against fatma.txt\n",
            "Testing juma.txt against john.txt\n",
            "\n",
            "Started testing:fatma.txt\n",
            "Testing fatma.txt against juma.txt\n",
            "Testing fatma.txt against fatma.txt\n",
            "Testing fatma.txt against john.txt\n",
            "\n",
            "Started testing:john.txt\n",
            "Testing john.txt against juma.txt\n",
            "Testing john.txt against fatma.txt\n",
            "Testing john.txt against john.txt\n",
            "\n",
            "('fatma.txt', 'john.txt', 0.14806887549598566)\n",
            "('john.txt', 'juma.txt', 0.5465972177348937)\n",
            "('juma.txt', 'juma.txt', 1.0000000000000004)\n",
            "('fatma.txt', 'fatma.txt', 1.0)\n",
            "('john.txt', 'john.txt', 1.0)\n",
            "('fatma.txt', 'juma.txt', 0.18643448370323362)\n",
            "\n",
            "Time taken: 0.004704713821411133\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g6z82hou8J4t",
        "outputId": "97f66610-b4b1-41a5-c648-d807b6edaf3c"
      },
      "source": [
        "#Parallel [Manual] Part 1\n",
        "start=time.time()\n",
        "ans=check_plagiarism(s_vectors[:len(s_vectors)//2])\n",
        "\n",
        "for data in ans:\n",
        "    print(data)\n",
        "end=time.time()\n",
        "print()\n",
        "print(\"Time taken:\", end-start)"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting process...\n",
            "Started testing:juma.txt\n",
            "Testing juma.txt against juma.txt\n",
            "Testing juma.txt against fatma.txt\n",
            "Testing juma.txt against john.txt\n",
            "\n",
            "('fatma.txt', 'john.txt', 0.14806887549598566)\n",
            "('john.txt', 'juma.txt', 0.5465972177348937)\n",
            "('juma.txt', 'juma.txt', 1.0000000000000004)\n",
            "('fatma.txt', 'fatma.txt', 1.0)\n",
            "('john.txt', 'john.txt', 1.0)\n",
            "('fatma.txt', 'juma.txt', 0.18643448370323362)\n",
            "\n",
            "Time taken: 0.008398771286010742\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CS344D-c8J1a",
        "outputId": "219b2105-7e75-4f38-8b18-42e0e29b76bd"
      },
      "source": [
        "#Parallel [Manual] Part 2\n",
        "start=time.time()\n",
        "ans=check_plagiarism(s_vectors[len(s_vectors)//2:])\n",
        "\n",
        "for data in ans:\n",
        "    print(data)\n",
        "end=time.time()\n",
        "print()\n",
        "print(\"Time taken:\", end-start)"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting process...\n",
            "Started testing:fatma.txt\n",
            "Testing fatma.txt against juma.txt\n",
            "Testing fatma.txt against fatma.txt\n",
            "Testing fatma.txt against john.txt\n",
            "\n",
            "Started testing:john.txt\n",
            "Testing john.txt against juma.txt\n",
            "Testing john.txt against fatma.txt\n",
            "Testing john.txt against john.txt\n",
            "\n",
            "('fatma.txt', 'john.txt', 0.14806887549598566)\n",
            "('john.txt', 'juma.txt', 0.5465972177348937)\n",
            "('juma.txt', 'juma.txt', 1.0000000000000004)\n",
            "('fatma.txt', 'fatma.txt', 1.0)\n",
            "('john.txt', 'john.txt', 1.0)\n",
            "('fatma.txt', 'juma.txt', 0.18643448370323362)\n",
            "\n",
            "Time taken: 0.0029540061950683594\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jorU1AcFMXJq"
      },
      "source": [
        "Ways to achieve data parallelism:\n",
        "1. Divide s_vectors in parts (more likely)\n",
        "2. Divide s_vectors[0][1] in parts (potential)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYc0Srm6MWN6"
      },
      "source": [
        "s_vectors[:len(s_vectors)//2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBnOp2aVKNDc",
        "outputId": "efe8b325-9a2a-45ee-d92a-f57fdec1bc1f"
      },
      "source": [
        "#Multiprocessing approach\n",
        "import multiprocessing\n",
        "import os\n",
        "start=time.time()\n",
        "# def worker1(func1): \n",
        "#   func1(m)\n",
        "  \n",
        "\n",
        "start=time.time()\n",
        "\n",
        "pool = multiprocessing.Pool(processes=2) \n",
        "\n",
        "\n",
        "\n",
        "l1 = s_vectors[:len(s_vectors)//2]\n",
        "l2 = s_vectors[len(s_vectors)//2:]\n",
        "\n",
        "\n",
        "result = pool.map(check_plagiarism, [l1,l2])\n",
        "\n",
        "for i in result:\n",
        "  print(i)\n",
        "\n",
        "# print(ans)\n",
        "\n",
        "end=time.time()\n",
        "\n",
        "# ty.append(\"Multiprocessing [50000 elements]\")\n",
        "# t.append(end-start)\n",
        "\n",
        "print(\"Time taken: \",end-start)"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting process...\n",
            "Starting process...\n",
            "Started testing:juma.txt\n",
            "Testing juma.txt against juma.txt\n",
            "Started testing:fatma.txt\n",
            "Testing juma.txt against fatma.txt\n",
            "Testing fatma.txt against juma.txt\n",
            "Testing juma.txt against john.txt\n",
            "Testing fatma.txt against fatma.txt\n",
            "Testing fatma.txt against john.txt\n",
            "\n",
            "\n",
            "Started testing:john.txt\n",
            "Testing john.txt against juma.txt\n",
            "Testing john.txt against fatma.txt\n",
            "Testing john.txt against john.txt\n",
            "\n",
            "{('fatma.txt', 'john.txt', 0.14806887549598566), ('john.txt', 'juma.txt', 0.5465972177348937), ('john.txt', 'john.txt', 1.0), ('juma.txt', 'juma.txt', 1.0000000000000004), ('fatma.txt', 'fatma.txt', 1.0), ('fatma.txt', 'juma.txt', 0.18643448370323362)}\n",
            "{('fatma.txt', 'john.txt', 0.14806887549598566), ('john.txt', 'juma.txt', 0.5465972177348937), ('john.txt', 'john.txt', 1.0), ('juma.txt', 'juma.txt', 1.0000000000000004), ('fatma.txt', 'fatma.txt', 1.0), ('fatma.txt', 'juma.txt', 0.18643448370323362)}\n",
            "0.0993509292602539\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}